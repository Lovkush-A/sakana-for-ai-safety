# Title: Demeaning the probes
# Experiment description: First have to identify the average activations across a medium sized dataset, that should be downloaded from the internet. Then need to subtract this from the probe.
## Run 0: Baseline
Results: {'layer_9.0_beta_1.0': 0.0070885481852315, 'layer_9.0_beta_3.0': 0.06547090112640801, 'layer_9.0_beta_5.0': 0.06672298706716727, 'layer_10.0_beta_1.0': 0.027939090529828934, 'layer_10.0_beta_3.0': 0.10925740508969539, 'layer_10.0_beta_5.0': 0.10842563621193158, 'layer_11.0_beta_1.0': 0.042952127659574464, 'layer_11.0_beta_3.0': 0.11717980809345009, 'layer_11.0_beta_5.0': 0.10216781393408424, 'layer_12.0_beta_1.0': 0.02252085940759277, 'layer_12.0_beta_3.0': 0.10008083020442216, 'layer_12.0_beta_5.0': 0.051295890696704205}
Description: Baseline results.

## Experiment Plan
Run 1: Implement demeaning using WikiText-2 dataset
- Download WikiText-2 dataset
- Calculate average activations across this dataset
- Subtract these averages from the steering vectors before applying them
- Use the same beta values as baseline [1, 3, 5]

Run 2: Try a different dataset (C4) for demeaning
- Use C4 dataset which is larger and more diverse
- Calculate average activations across this dataset
- Compare results with Run 1 to see if dataset choice matters
- Hypothesis: A more diverse dataset might provide better background statistics

Run 3: Experiment with different scaling factors for the demeaned component
- Try different scaling factors for the background component (demean_factor=0.5)
- Explore if partial demeaning works better than full demeaning
- Hypothesis: Partial demeaning might preserve some useful directional information while removing noise

Run 4: Combine best approaches from previous runs (if needed)
- Based on results from Runs 1-3, implement the best combination

Run 5: Final optimization (if needed)
- Fine-tune the best approach from previous runs
