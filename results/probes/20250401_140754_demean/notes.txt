# Title: Demeaning the probes
# Experiment description: First have to identify the average activations across a medium sized dataset, that should be downloaded from the internet. Then need to subtract this from the probe.
## Run 0: Baseline
Results: Baseline results is we achieve about 10% accuracy on the test set, using basic probe.
Description: Baseline results.

## Run 1: Basic Demeaning Implementation
Description: Downloaded WikiText-103 dataset (500 examples) to compute background mean activations. Implemented demeaning by subtracting these background means from the steering vectors before applying them. This should help remove general language biases from the steering vectors, making them more specific to the task.

## Run 2: Scaling the Demeaning Component
Description: Building on Run 1, we now experiment with different scaling factors (0.5, 1.0, 2.0) specifically for the demeaning component. This allows us to control how much of the background mean is subtracted from the steering vector. A scaling factor of 0.5 means we subtract only half of the background mean, while 2.0 means we subtract twice the background mean. This helps us find the optimal balance between keeping task-specific information and removing general language biases.

## Run 3: Cross-Layer Demeaning
Description: In this experiment, we explore using different layers for the steering vector and the demeaning component. For example, we might use the steering vector from layer 10 but demean it using the background mean from layer 12. This tests whether the general language biases captured in different layers might be more effective for demeaning than using the same layer for both. We use the best demean scaling factor from Run 2 and try all possible combinations of steering and demeaning layers.

## Run 4: Layer-Specific Demeaning Scales
Description: Building on our previous experiments, we now implement layer-specific demeaning scales. Different layers in the model capture different types of information, so it makes sense that the optimal demeaning scale might vary by layer. In this experiment, we assign each layer its own demeaning scale (initially based on layer depth) and evaluate performance. This approach allows us to fine-tune the demeaning process for each layer individually, potentially leading to better overall performance.
